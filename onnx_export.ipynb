{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(10, 3, 224, 224)\n",
      "      %1 : Float(64, 3, 11, 11)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(192, 64, 5, 5)\n",
      "      %4 : Float(192)\n",
      "      %5 : Float(384, 192, 3, 3)\n",
      "      %6 : Float(384)\n",
      "      %7 : Float(256, 384, 3, 3)\n",
      "      %8 : Float(256)\n",
      "      %9 : Float(256, 256, 3, 3)\n",
      "      %10 : Float(256)\n",
      "      %11 : Float(4096, 9216)\n",
      "      %12 : Float(4096)\n",
      "      %13 : Float(4096, 4096)\n",
      "      %14 : Float(4096)\n",
      "      %15 : Float(1000, 4096)\n",
      "      %16 : Float(1000)) {\n",
      "  %17 : Float(10, 64, 55, 55) = Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%0, %1, %2), scope: AlexNet/Sequential[features]/Conv2d[0]\n",
      "  %18 : Float(10, 64, 55, 55) = Relu(%17), scope: AlexNet/Sequential[features]/ReLU[1]\n",
      "  %19 : Float(10, 64, 27, 27) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18), scope: AlexNet/Sequential[features]/MaxPool2d[2]\n",
      "  %20 : Float(10, 192, 27, 27) = Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%19, %3, %4), scope: AlexNet/Sequential[features]/Conv2d[3]\n",
      "  %21 : Float(10, 192, 27, 27) = Relu(%20), scope: AlexNet/Sequential[features]/ReLU[4]\n",
      "  %22 : Float(10, 192, 13, 13) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%21), scope: AlexNet/Sequential[features]/MaxPool2d[5]\n",
      "  %23 : Float(10, 384, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %5, %6), scope: AlexNet/Sequential[features]/Conv2d[6]\n",
      "  %24 : Float(10, 384, 13, 13) = Relu(%23), scope: AlexNet/Sequential[features]/ReLU[7]\n",
      "  %25 : Float(10, 256, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %7, %8), scope: AlexNet/Sequential[features]/Conv2d[8]\n",
      "  %26 : Float(10, 256, 13, 13) = Relu(%25), scope: AlexNet/Sequential[features]/ReLU[9]\n",
      "  %27 : Float(10, 256, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%26, %9, %10), scope: AlexNet/Sequential[features]/Conv2d[10]\n",
      "  %28 : Float(10, 256, 13, 13) = Relu(%27), scope: AlexNet/Sequential[features]/ReLU[11]\n",
      "  %29 : Float(10, 256, 6, 6) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28), scope: AlexNet/Sequential[features]/MaxPool2d[12]\n",
      "  %30 : Float(10, 9216) = Flatten[axis=1](%29), scope: AlexNet\n",
      "  %31 : Float(10, 9216), %32 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%30), scope: AlexNet/Sequential[classifier]/Dropout[0]\n",
      "  %33 : Float(10, 4096) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%31, %11, %12), scope: AlexNet/Sequential[classifier]/Linear[1]\n",
      "  %34 : Float(10, 4096) = Relu(%33), scope: AlexNet/Sequential[classifier]/ReLU[2]\n",
      "  %35 : Float(10, 4096), %36 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%34), scope: AlexNet/Sequential[classifier]/Dropout[3]\n",
      "  %37 : Float(10, 4096) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%35, %13, %14), scope: AlexNet/Sequential[classifier]/Linear[4]\n",
      "  %38 : Float(10, 4096) = Relu(%37), scope: AlexNet/Sequential[classifier]/ReLU[5]\n",
      "  %39 : Float(10, 1000) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%38, %15, %16), scope: AlexNet/Sequential[classifier]/Linear[6]\n",
      "  return (%39);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"An example for creating a dump of a pytorch file, w/o generating a proto file\n",
    "\n",
    "This requires torch with ONNX support, which currently mesans using the master \n",
    "pytorch branch, and compiling pytorch from sources.\n",
    "\"\"\"\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "\n",
    "class DummyFile(object):\n",
    "    \"\"\"This is a fake file class, to be used in case that \n",
    "    we don't want to create a real prototxt file.\n",
    "    \"\"\"\n",
    "    def write(*args):\n",
    "        pass\n",
    "\n",
    "dummy_file = DummyFile()\n",
    "dummy_input = Variable(torch.randn(10, 3, 224, 224)).cuda()\n",
    "model = torchvision.models.alexnet(pretrained=True).cuda()\n",
    "model.eval()\n",
    "\n",
    "# The export method writes a representation of the model to stdout,\n",
    "# when verbose=True.\n",
    "# We can suppress the creation of the binary protobuf file, by\n",
    "# passing a fake file interface.\n",
    "# We can also use this interface to capture the protobuf content,\n",
    "# by implementing the write() method.\n",
    "torch.onnx.export(model, dummy_input, dummy_file, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is an example of capturing the ONNX textual representation in a\n",
    "string, instead of sending it to the console.\n",
    "\n",
    "This requires python >= 3.4\n",
    "\"\"\"\n",
    "\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# In this example, we want to capture the verbose textual output\n",
    "# in a string, and we want to suppress the output to stdio.\n",
    "f = io.StringIO()\n",
    "with redirect_stdout(f):\n",
    "    dummy_file = DummyFile()\n",
    "    torch.onnx.export(model, dummy_input, dummy_file, verbose=True)\n",
    "onnx_str = f.getvalue()\n",
    "#print(onnx_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
